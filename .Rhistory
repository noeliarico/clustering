"euc", # 2 - euclidean
"che", # 3 - chebyshev
# L1 distance measures ////////////////////////////////////////////////////////
"can", # 4 - canberra
"gow", # 5 - gower
# Inner product distance measures /////////////////////////////////////////////
"jac", # 6 - jaccard
"cos", # 7 - cosine
# Squared Chord distance measures /////////////////////////////////////////////
"sqc", # 8 - SqrdChrd
"mat", # 9 - matusita
# Squared L2 distance measures ////////////////////////////////////////////////
"cla", # 10 - clark
"ney", # 11 - neyman
"pea", # 12 - pearson
"tri", # 13 - trngDiscr
# Vicissitude distance measures ///////////////////////////////////////////////
"vsd", # 14 - VSD3
"msc", # 15 - maxSymmSq
# Scoring distance functions
#"plurality", # 101
"bordaCount" # 102
)
selected_distances <- c(1:15)[!(c(1:15) %in% c(5,8))]
distances[selected_distances]
train_rkmeans <- function(points, cen, iter.max = 100) {
points <- points %>% select(-cluster)
points <- as_tibble(apply(points, 2, normalize))
#print(head(points))
#pb <- txtProgressBar(min = 0, max = 15)
desired_length <- length(selected_distances) + 1 # selected distances + social choice function
results <- vector(mode = "list", length = desired_length)
# Calculate the values with the individuals distances
for(i in 1:length(selected_distances)) {
#setTxtProgressBar(pb, i)
set.seed(2020)
out_rkmeans <- rkmeans(x = points, centers = cen, iter.max = iter.max, nstart = 1,
trace = FALSE, selected_distances, dist = i)
results[[i]] <- out_rkmeans
}
#
# setTxtProgressBar(pb, 14)
# set.seed(2020)
# out_rkmeans <- rkmeans(x = points, centers = cen, iter.max = 100, nstart = 1,
#                        trace = FALSE, distances = 1:13, dist = 101)
# results[[14]] <- out_rkmeans
#
#setTxtProgressBar(pb, 15)
set.seed(2020) # Borda count
out_rkmeans <- rkmeans(x = points, centers = cen, iter.max = 100, nstart = 1,
trace = FALSE, selected_distances, dist = 102)
results[[length(selected_distances)+1]] <- out_rkmeans
#close(pb)
names(results) <- distances[selected_distances]
return(results)
}
save.image()
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, 5)
out_points
source('~/Desktop/Github/clustering/02.method/rkmeans/rkmeans.R', echo=TRUE)
train_rkmeans <- function(points, cen, iter.max = 100) {
points <- points %>% select(-cluster)
points <- as_tibble(apply(points, 2, normalize))
#print(head(points))
#pb <- txtProgressBar(min = 0, max = 15)
desired_length <- length(selected_distances) + 1 # selected distances + social choice function
results <- vector(mode = "list", length = desired_length)
# Calculate the values with the individuals distances
for(i in 1:length(selected_distances)) {
#setTxtProgressBar(pb, i)
set.seed(2020)
out_rkmeans <- rkmeans(x = points, centers = cen, iter.max = iter.max, nstart = 1,
trace = FALSE, selected_distances, dist = i)
results[[i]] <- out_rkmeans
}
#
# setTxtProgressBar(pb, 14)
# set.seed(2020)
# out_rkmeans <- rkmeans(x = points, centers = cen, iter.max = 100, nstart = 1,
#                        trace = FALSE, distances = 1:13, dist = 101)
# results[[14]] <- out_rkmeans
#
#setTxtProgressBar(pb, 15)
set.seed(2020) # Borda count
out_rkmeans <- rkmeans(x = points, centers = cen, iter.max = 100, nstart = 1,
trace = FALSE, selected_distances, dist = 102)
results[[length(selected_distances)+1]] <- out_rkmeans
#close(pb)
names(results) <- distances[selected_distances]
return(results)
}
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, 5)
out_points <- train_rkmeans(points, 5, 5, iter.max = 1)
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
warnings()
train_rkmeans <- function(points, cen, iter.max = 100) {
points <- points %>% select(-cluster)
points <- as_tibble(apply(points, 2, normalize))
#print(head(points))
#pb <- txtProgressBar(min = 0, max = 15)
desired_length <- length(selected_distances) + 1 # selected distances + social choice function
results <- vector(mode = "list", length = desired_length)
# Calculate the values with the individuals distances
for(i in 1:length(selected_distances)) {
#setTxtProgressBar(pb, i)
set.seed(2020)
out_rkmeans <- rkmeans(x = points, centers = cen, iter.max = iter.max, nstart = 1,
trace = FALSE, selected_distances, dist = selected_distances[i])
results[[i]] <- out_rkmeans
}
#
# setTxtProgressBar(pb, 14)
# set.seed(2020)
# out_rkmeans <- rkmeans(x = points, centers = cen, iter.max = 100, nstart = 1,
#                        trace = FALSE, distances = 1:13, dist = 101)
# results[[14]] <- out_rkmeans
#
#setTxtProgressBar(pb, 15)
set.seed(2020) # Borda count
out_rkmeans <- rkmeans(x = points, centers = cen, iter.max = 100, nstart = 1,
trace = FALSE, selected_distances, dist = 102)
results[[length(selected_distances)+1]] <- out_rkmeans
#close(pb)
names(results) <- distances[selected_distances]
return(results)
}
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
out_points <- train_rkmeans(points, 5, iter.max = 1)
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
# Load the methods just in case...
dyn.load("02.method/distances/distances.so")
dyn.load("02.method/rkmeans/rkmeans.so")
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
train_rkmeans <- function(points, cen, iter.max = 100) {
points <- points %>% select(-cluster)
points <- as_tibble(apply(points, 2, normalize))
#print(head(points))
#pb <- txtProgressBar(min = 0, max = 15)
desired_length <- length(selected_distances) + 1 # selected distances + social choice function
results <- vector(mode = "list", length = desired_length)
# Calculate the values with the individuals distances
for(i in 1:length(selected_distances)) {
#setTxtProgressBar(pb, i)
set.seed(2020)
out_rkmeans <- rkmeans(x = points, centers = cen, iter.max = iter.max, nstart = 1,
trace = FALSE, selected_distances, dist = selected_distances[i])
results[[i]] <- out_rkmeans
}
#
# setTxtProgressBar(pb, 14)
# set.seed(2020)
# out_rkmeans <- rkmeans(x = points, centers = cen, iter.max = 100, nstart = 1,
#                        trace = FALSE, distances = 1:13, dist = 101)
# results[[14]] <- out_rkmeans
#
#setTxtProgressBar(pb, 15)
# set.seed(2020) # Borda count
# out_rkmeans <- rkmeans(x = points, centers = cen, iter.max = 100, nstart = 1,
#                        trace = FALSE, selected_distances, dist = 102)
# results[[length(selected_distances)+1]] <- out_rkmeans
#close(pb)
names(results) <- distances[selected_distances]
return(results)
}
train_rkmeans <- function(points, cen, iter.max = 100) {
points <- points %>% select(-cluster)
points <- as_tibble(apply(points, 2, normalize))
#print(head(points))
#pb <- txtProgressBar(min = 0, max = 15)
desired_length <- length(selected_distances) + 1 # selected distances + social choice function
results <- vector(mode = "list", length = desired_length)
# Calculate the values with the individuals distances
for(i in 1:length(selected_distances)) {
#setTxtProgressBar(pb, i)
set.seed(2020)
out_rkmeans <- rkmeans(x = points, centers = cen, iter.max = iter.max, nstart = 1,
trace = FALSE, selected_distances, dist = selected_distances[i])
results[[i]] <- out_rkmeans
}
#
# setTxtProgressBar(pb, 14)
# set.seed(2020)
# out_rkmeans <- rkmeans(x = points, centers = cen, iter.max = 100, nstart = 1,
#                        trace = FALSE, distances = 1:13, dist = 101)
# results[[14]] <- out_rkmeans
#
#setTxtProgressBar(pb, 15)
# set.seed(2020) # Borda count
# out_rkmeans <- rkmeans(x = points, centers = cen, iter.max = 100, nstart = 1,
#                        trace = FALSE, selected_distances, dist = 102)
# results[[length(selected_distances)+1]] <- out_rkmeans
#close(pb)
results[[length(selected_distances)+1]] <- NULL
names(results) <- distances[selected_distances]
return(results)
}
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
rkmeans <-
function(x, centers, iter.max = 10L, nstart = 1L, trace = FALSE, selected_distances = c(1, 2), dist = 2)
{
#.Mimax <- .Machine$integer.max
# Wrapper for calling the C function that execute kmeans
Crkmeans <- function() {
Z <- .C("rkmeans", x, nobjects, nvariables,
centers = centers, k,
c1 = integer(nobjects), iter = iter.max,
nc = integer(k), wss = wss, ndist = ndist,
dist = as.integer(dist),
sd = selected_distances)
if(any(Z$nc == 0)) {
warning("empty cluster: try a better set of initial centers",
call. = FALSE)
Z$ifault <- 2L
}
if(Z$iter > iter.max) {
warning(sprintf(ngettext(iter.max,
"did not converge in %d iteration",
"did not converge in %d iterations"),
iter.max), call. = FALSE, domain = NA)
}
Z
}
x <- as.matrix(x) # data to matrix so it can be used in C
#print(x)
# Number of "distances" = Number of elected distances + 1 social choice function
ndist <- as.integer(selected_distances)
## as.integer(<too large>) gives NA ==> not allowing too large nrow() / ncol():
nobjects <- as.integer(nrow(x)); if(is.na(nobjects)) stop("Too much objects")
nvariables <- as.integer(ncol(x)); if(is.na(nvariables)) stop("Too much variables")
# Check if the parameter centers is valid
if(missing(centers))
stop("'centers' must be a number or a matrix")
storage.mode(x) <- "double"
if(length(centers) == 1L) {
# Centers can be the number of centers or a vector with an inicilization
# If the center is a number then we create k = centers random centers
k <- centers
## we need to avoid duplicates here
if(nstart == 1L)
centers <- x[sample.int(nobjects, k), , drop = FALSE]
if(nstart >= 2L || any(duplicated(centers))) {
cn <- unique(x)
mm <- nrow(cn)
if(mm < k)
stop("more cluster centers than distinct data points.")
centers <- cn[sample.int(mm, k), , drop=FALSE]
}
} else {
centers <- as.matrix(centers)
if(any(duplicated(centers)))
stop("initial centers are not distinct")
cn <- NULL
k <- nrow(centers)
if(nobjects < k)
stop("more cluster centers than data points")
}
k <- as.integer(k) # Number of clusters to be created
if(is.na(k)) stop("'invalid value of 'k'")
wss <- matrix(rep(double(k), length(selected_distances)), ncol = k)
#wss <- double(k)
#if (k == 1L) nmeth <- 3L # Hartigan-Wong, (Fortran) needs k > 1
iter.max <- as.integer(iter.max)
if(is.na(iter.max) || iter.max < 1L) stop("'iter.max' must be positive")
if(ncol(x) != ncol(centers))
stop("must have same number of columns in 'x' and 'centers'")
storage.mode(centers) <- "double"
Z <- Crkmeans()
#print("wss")
#print(Z$wss)
best <- sum(Z$wss) # original
#print(ndist)
#Z$iter <- Z$iter -1 # noelia
best <- rowSums(Z$wss)# noelia
if(nstart >= 2L && !is.null(cn)) {
for(i in 2:nstart) {
centers <- cn[sample.int(mm, k), , drop=FALSE]
ZZ <- Crkmeans()
if((z <- sum(ZZ$wss)) < best) {
Z <- ZZ
best <- z
}
}
}
centers <- matrix(Z$centers, k)
dimnames(centers) <- list(1L:k, dimnames(x)[[2L]])
cluster <- Z$c1
if(!is.null(rn <- rownames(x)))
names(cluster) <- rn
totss <- sum(scale(x, scale = FALSE)^2)
names(best) <- paste0("errord_",selected_distances)
structure(list(cluster = cluster, centers = centers, totss = totss,
withinss = Z$wss, tot.withinss = best,
betweenss = totss - best, size = Z$nc,
iter = Z$iter, ifault = Z$ifault),
class = "rkmeans")
}
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
source('~/Desktop/Github/clustering/02.method/rkmeans/rkmeans.R', echo=TRUE)
# Load the methods just in case...
dyn.load("02.method/distances/distances.so")
dyn.load("02.method/rkmeans/rkmeans.so")
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
# Load the methods just in case...
dyn.load("02.method/distances/distances.so")
dyn.load("02.method/rkmeans/rkmeans.so")
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
# Load the methods just in case...
dyn.load("02.method/distances/distances.so")
dyn.load("02.method/rkmeans/rkmeans.so")
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
source('~/Desktop/Github/clustering/02.method/rkmeans/rkmeans.R', echo=TRUE)
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
# Load the methods just in case...
dyn.load("02.method/distances/distances.so")
dyn.load("02.method/rkmeans/rkmeans.so")
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
errors <- calculate_errors(out_points)
errors <- sorted_errors_by_dataset(errors)
rankingsOfErrors <- lapply(errors, ranking)
rankingsOfErrors <- profile_of_rankings(Reduce(bind_rows, rankingsOfErrors))
rankingsOfErrors_borda <- borda_count(rankingsOfErrors)
rankingsOfErrors_borda
rankingsOfErrors
# Number of clusters of each dataset
number_of_clusters <- unlist(lapply(datasets, function(x) x %>% distinct(cluster) %>% nrow()))
# Empty list to store the results for each dataset in the list "datasets"
datasets_results <- vector(mode = "list", length = length(datasets))
#for(i in 1:length(datasets)) {
for(i in 1:10) {
results <- train_rkmeans(datasets[[i]], number_of_clusters[i])
datasets_results[[i]] <- results
}
# For each dataset, creates a matrix where the rows represent the
# distance measure use for the clustering process
# The row shows the error calculated with each of the distance measures for
# every version of the clustering
results_dataset_errors <- lapply(datasets_results[1:10], calculate_errors)
names(results_dataset_errors) <- names(datasets[1:10])
results_dataset_errors_sorted <- lapply(results_dataset_errors, sorted_errors_by_dataset)
# Create ranking
(rankingsOfErrors <- lapply(results_dataset_errors_sorted, function(x) lapply(x, ranking)))
rankingsOfErrors <- lapply(rankingsOfErrors, function(x) Reduce(bind_rows, x))
rankingsOfErrors <- lapply(rankingsOfErrors, profile_of_rankings)
rankingsOfErrors_borda <- lapply(rankingsOfErrors, borda_count)
rankingsOfErrors_borda
the_seed
source('~/Desktop/Github/clustering/03.experiments/01.training_functions.R', echo=TRUE)
source('~/Desktop/Github/clustering/03.experiments/01.training_functions.R', echo=TRUE)
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
errors <- calculate_errors(out_points)
errors
errors <- sorted_errors_by_dataset(errors)
rankingsOfErrors <- lapply(errors, ranking)
rankingsOfErrors <- profile_of_rankings(Reduce(bind_rows, rankingsOfErrors))
rankingsOfErrors_borda <- borda_count(rankingsOfErrors)
errors
source('~/Desktop/Github/clustering/04.results/01.results_functions.R', echo=TRUE)
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
errors <- calculate_errors(out_points)
errors
# Input: matrix of errors obtained after applying "calculate_errors"
#
sorted_errors_by_dataset <- function(errors_of_one_dataset) {
ranking_of_errors <- lapply(1:nrow(errors_of_one_dataset), function(x) {
sort(errors_of_one_dataset[x,])
})
names(ranking_of_errors) <- selected_distances
ranking_of_errors
}
# Input: results of one datasets, taken from a single
# element of the list datasets_results
# Calculates for each distance that was used for training the dataset the
# errors computed which each of the distance
calculate_errors <- function(results_of_one_dataset) {
errors_one_dataset <- sapply(results_of_one_dataset, function(x) x$tot.withinss)
rownames(errors_one_dataset) <- c(paste0("error_d", selected_distances))
errors_one_dataset
#colSums(errorsd1)
}
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
out_points
source('~/Desktop/Github/clustering/03.experiments/01.training_functions.R', echo=TRUE)
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
out_points
errors <- calculate_errors(out_points)
errors
errors <- sorted_errors_by_dataset(errors)
rankingsOfErrors <- lapply(errors, ranking)
rankingsOfErrors <- profile_of_rankings(Reduce(bind_rows, rankingsOfErrors))
rankingsOfErrors_borda <- borda_count(rankingsOfErrors)
rankingsOfErrors_borda
# Number of clusters of each dataset
number_of_clusters <- unlist(lapply(datasets, function(x) x %>% distinct(cluster) %>% nrow()))
# Empty list to store the results for each dataset in the list "datasets"
datasets_results <- vector(mode = "list", length = length(datasets))
#for(i in 1:length(datasets)) {
for(i in 1:10) {
results <- train_rkmeans(datasets[[i]], number_of_clusters[i])
datasets_results[[i]] <- results
}
# For each dataset, creates a matrix where the rows represent the
# distance measure use for the clustering process
# The row shows the error calculated with each of the distance measures for
# every version of the clustering
results_dataset_errors <- lapply(datasets_results[1:10], calculate_errors)
names(results_dataset_errors) <- names(datasets[1:10])
results_dataset_errors_sorted <- lapply(results_dataset_errors, sorted_errors_by_dataset)
# Create ranking
(rankingsOfErrors <- lapply(results_dataset_errors_sorted, function(x) lapply(x, ranking)))
rankingsOfErrors <- lapply(rankingsOfErrors, function(x) Reduce(bind_rows, x))
rankingsOfErrors <- lapply(rankingsOfErrors, profile_of_rankings)
rankingsOfErrors_borda <- lapply(rankingsOfErrors, borda_count)
rankingsOfErrors_borda
source('~/Desktop/Github/clustering/Untitled.R', echo=TRUE)
library(clusterlab)
library(tidyverse)
# 1830 la peor es Euclídea!!!!
#2456
#1617
the_seed <- 2456
# Create a dataset of 2 varibles with 5 clustes of three points each
data <- clusterlab(centers = 5, # the number of clusters to simulate
# the number of units of the radius of the circle on which the clusters are generated
r = 2,
# the number of samples in each cluster
numbervec = c(3, 3, 3, 3, 3),
# standard deviation of each cluster
sdvec = c(1, 3, 2, 1, 1),
alphas = c(3, 5, 1, 4, 2),
# the number of features for the data
features = 2,
seed = the_seed, showplots = FALSE)
(points <- as_tibble(t(data$synthetic_data)) %>% rename(x = 1, y = 2))
#normalize <- function(x){((x-min(x))/(max(x)-min(x)))} # this is already done in train_rkmeans
#points <- as_tibble(apply(points, 2, normalize))
points <- points %>% mutate(cluster = data$identity_matrix$cluster)
# Load the methods just in case...
dyn.load("02.method/distances/distances.so")
dyn.load("02.method/rkmeans/rkmeans.so")
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
errors <- calculate_errors(out_points)
errors <- sorted_errors_by_dataset(errors)
rankingsOfErrors <- lapply(errors, ranking)
rankingsOfErrors <- profile_of_rankings(Reduce(bind_rows, rankingsOfErrors))
rankingsOfErrors_borda <- borda_count(rankingsOfErrors)
rankingsOfErrors_borda
