## we need to avoid duplicates here
if(nstart == 1L)
centers <- x[sample.int(nobjects, k), , drop = FALSE]
if(nstart >= 2L || any(duplicated(centers))) {
cn <- unique(x)
mm <- nrow(cn)
if(mm < k)
stop("more cluster centers than distinct data points.")
centers <- cn[sample.int(mm, k), , drop=FALSE]
}
} else {
centers <- as.matrix(centers)
if(any(duplicated(centers)))
stop("initial centers are not distinct")
cn <- NULL
k <- nrow(centers)
if(nobjects < k)
stop("more cluster centers than data points")
}
k <- as.integer(k) # Number of clusters to be created
if(is.na(k)) stop("'invalid value of 'k'")
wss <- matrix(rep(double(k), length(selected_distances)), ncol = k)
#wss <- double(k)
#if (k == 1L) nmeth <- 3L # Hartigan-Wong, (Fortran) needs k > 1
iter.max <- as.integer(iter.max)
if(is.na(iter.max) || iter.max < 1L) stop("'iter.max' must be positive")
if(ncol(x) != ncol(centers))
stop("must have same number of columns in 'x' and 'centers'")
storage.mode(centers) <- "double"
Z <- Crkmeans()
#print("wss")
#print(Z$wss)
best <- sum(Z$wss) # original
#print(ndist)
#Z$iter <- Z$iter -1 # noelia
best <- rowSums(Z$wss)# noelia
if(nstart >= 2L && !is.null(cn)) {
for(i in 2:nstart) {
centers <- cn[sample.int(mm, k), , drop=FALSE]
ZZ <- Crkmeans()
if((z <- sum(ZZ$wss)) < best) {
Z <- ZZ
best <- z
}
}
}
centers <- matrix(Z$centers, k)
dimnames(centers) <- list(1L:k, dimnames(x)[[2L]])
cluster <- Z$c1
if(!is.null(rn <- rownames(x)))
names(cluster) <- rn
totss <- sum(scale(x, scale = FALSE)^2)
names(best) <- paste0("errord_",selected_distances)
structure(list(cluster = cluster, centers = centers, totss = totss,
withinss = Z$wss, tot.withinss = best,
betweenss = totss - best, size = Z$nc,
iter = Z$iter, ifault = Z$ifault),
class = "rkmeans")
}
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
source('~/Desktop/Github/clustering/02.method/rkmeans/rkmeans.R', echo=TRUE)
# Load the methods just in case...
dyn.load("02.method/distances/distances.so")
dyn.load("02.method/rkmeans/rkmeans.so")
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
# Load the methods just in case...
dyn.load("02.method/distances/distances.so")
dyn.load("02.method/rkmeans/rkmeans.so")
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
# Load the methods just in case...
dyn.load("02.method/distances/distances.so")
dyn.load("02.method/rkmeans/rkmeans.so")
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
source('~/Desktop/Github/clustering/02.method/rkmeans/rkmeans.R', echo=TRUE)
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
# Load the methods just in case...
dyn.load("02.method/distances/distances.so")
dyn.load("02.method/rkmeans/rkmeans.so")
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
errors <- calculate_errors(out_points)
errors <- sorted_errors_by_dataset(errors)
rankingsOfErrors <- lapply(errors, ranking)
rankingsOfErrors <- profile_of_rankings(Reduce(bind_rows, rankingsOfErrors))
rankingsOfErrors_borda <- borda_count(rankingsOfErrors)
rankingsOfErrors_borda
rankingsOfErrors
# Number of clusters of each dataset
number_of_clusters <- unlist(lapply(datasets, function(x) x %>% distinct(cluster) %>% nrow()))
# Empty list to store the results for each dataset in the list "datasets"
datasets_results <- vector(mode = "list", length = length(datasets))
#for(i in 1:length(datasets)) {
for(i in 1:10) {
results <- train_rkmeans(datasets[[i]], number_of_clusters[i])
datasets_results[[i]] <- results
}
# For each dataset, creates a matrix where the rows represent the
# distance measure use for the clustering process
# The row shows the error calculated with each of the distance measures for
# every version of the clustering
results_dataset_errors <- lapply(datasets_results[1:10], calculate_errors)
names(results_dataset_errors) <- names(datasets[1:10])
results_dataset_errors_sorted <- lapply(results_dataset_errors, sorted_errors_by_dataset)
# Create ranking
(rankingsOfErrors <- lapply(results_dataset_errors_sorted, function(x) lapply(x, ranking)))
rankingsOfErrors <- lapply(rankingsOfErrors, function(x) Reduce(bind_rows, x))
rankingsOfErrors <- lapply(rankingsOfErrors, profile_of_rankings)
rankingsOfErrors_borda <- lapply(rankingsOfErrors, borda_count)
rankingsOfErrors_borda
the_seed
source('~/Desktop/Github/clustering/03.experiments/01.training_functions.R', echo=TRUE)
source('~/Desktop/Github/clustering/03.experiments/01.training_functions.R', echo=TRUE)
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
errors <- calculate_errors(out_points)
errors
errors <- sorted_errors_by_dataset(errors)
rankingsOfErrors <- lapply(errors, ranking)
rankingsOfErrors <- profile_of_rankings(Reduce(bind_rows, rankingsOfErrors))
rankingsOfErrors_borda <- borda_count(rankingsOfErrors)
errors
source('~/Desktop/Github/clustering/04.results/01.results_functions.R', echo=TRUE)
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
errors <- calculate_errors(out_points)
errors
# Input: matrix of errors obtained after applying "calculate_errors"
#
sorted_errors_by_dataset <- function(errors_of_one_dataset) {
ranking_of_errors <- lapply(1:nrow(errors_of_one_dataset), function(x) {
sort(errors_of_one_dataset[x,])
})
names(ranking_of_errors) <- selected_distances
ranking_of_errors
}
# Input: results of one datasets, taken from a single
# element of the list datasets_results
# Calculates for each distance that was used for training the dataset the
# errors computed which each of the distance
calculate_errors <- function(results_of_one_dataset) {
errors_one_dataset <- sapply(results_of_one_dataset, function(x) x$tot.withinss)
rownames(errors_one_dataset) <- c(paste0("error_d", selected_distances))
errors_one_dataset
#colSums(errorsd1)
}
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
out_points
source('~/Desktop/Github/clustering/03.experiments/01.training_functions.R', echo=TRUE)
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
out_points
errors <- calculate_errors(out_points)
errors
errors <- sorted_errors_by_dataset(errors)
rankingsOfErrors <- lapply(errors, ranking)
rankingsOfErrors <- profile_of_rankings(Reduce(bind_rows, rankingsOfErrors))
rankingsOfErrors_borda <- borda_count(rankingsOfErrors)
rankingsOfErrors_borda
# Number of clusters of each dataset
number_of_clusters <- unlist(lapply(datasets, function(x) x %>% distinct(cluster) %>% nrow()))
# Empty list to store the results for each dataset in the list "datasets"
datasets_results <- vector(mode = "list", length = length(datasets))
#for(i in 1:length(datasets)) {
for(i in 1:10) {
results <- train_rkmeans(datasets[[i]], number_of_clusters[i])
datasets_results[[i]] <- results
}
# For each dataset, creates a matrix where the rows represent the
# distance measure use for the clustering process
# The row shows the error calculated with each of the distance measures for
# every version of the clustering
results_dataset_errors <- lapply(datasets_results[1:10], calculate_errors)
names(results_dataset_errors) <- names(datasets[1:10])
results_dataset_errors_sorted <- lapply(results_dataset_errors, sorted_errors_by_dataset)
# Create ranking
(rankingsOfErrors <- lapply(results_dataset_errors_sorted, function(x) lapply(x, ranking)))
rankingsOfErrors <- lapply(rankingsOfErrors, function(x) Reduce(bind_rows, x))
rankingsOfErrors <- lapply(rankingsOfErrors, profile_of_rankings)
rankingsOfErrors_borda <- lapply(rankingsOfErrors, borda_count)
rankingsOfErrors_borda
source('~/Desktop/Github/clustering/Untitled.R', echo=TRUE)
library(clusterlab)
library(tidyverse)
# 1830 la peor es Euclídea!!!!
#2456
#1617
the_seed <- 2456
# Create a dataset of 2 varibles with 5 clustes of three points each
data <- clusterlab(centers = 5, # the number of clusters to simulate
# the number of units of the radius of the circle on which the clusters are generated
r = 2,
# the number of samples in each cluster
numbervec = c(3, 3, 3, 3, 3),
# standard deviation of each cluster
sdvec = c(1, 3, 2, 1, 1),
alphas = c(3, 5, 1, 4, 2),
# the number of features for the data
features = 2,
seed = the_seed, showplots = FALSE)
(points <- as_tibble(t(data$synthetic_data)) %>% rename(x = 1, y = 2))
#normalize <- function(x){((x-min(x))/(max(x)-min(x)))} # this is already done in train_rkmeans
#points <- as_tibble(apply(points, 2, normalize))
points <- points %>% mutate(cluster = data$identity_matrix$cluster)
# Load the methods just in case...
dyn.load("02.method/distances/distances.so")
dyn.load("02.method/rkmeans/rkmeans.so")
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
errors <- calculate_errors(out_points)
errors <- sorted_errors_by_dataset(errors)
rankingsOfErrors <- lapply(errors, ranking)
rankingsOfErrors <- profile_of_rankings(Reduce(bind_rows, rankingsOfErrors))
rankingsOfErrors_borda <- borda_count(rankingsOfErrors)
rankingsOfErrors_borda
source('~/Desktop/Github/clustering/00.setup.R')
library(clusterlab)
library(tidyverse)
# 1830 la peor es Euclídea!!!!
#2456
#1617
the_seed <- 2456
# Create a dataset of 2 varibles with 5 clustes of three points each
data <- clusterlab(centers = 5, # the number of clusters to simulate
# the number of units of the radius of the circle on which the clusters are generated
r = 2,
# the number of samples in each cluster
numbervec = c(3, 3, 3, 3, 3),
# standard deviation of each cluster
sdvec = c(1, 3, 2, 1, 1),
alphas = c(3, 5, 1, 4, 2),
# the number of features for the data
features = 2,
seed = the_seed, showplots = FALSE)
(points <- as_tibble(t(data$synthetic_data)) %>% rename(x = 1, y = 2))
#normalize <- function(x){((x-min(x))/(max(x)-min(x)))} # this is already done in train_rkmeans
#points <- as_tibble(apply(points, 2, normalize))
points <- points %>% mutate(cluster = data$identity_matrix$cluster)
# Load the methods just in case...
dyn.load("02.method/distances/distances.so")
dyn.load("02.method/rkmeans/rkmeans.so")
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
errors <- calculate_errors(out_points)
warnings()
errors <- sorted_errors_by_dataset(errors)
rankingsOfErrors <- lapply(errors, ranking)
rankingsOfErrors <- profile_of_rankings(Reduce(bind_rows, rankingsOfErrors))
rankingsOfErrors_borda <- borda_count(rankingsOfErrors)
rankingsOfErrors_borda
# Number of clusters of each dataset
number_of_clusters <- unlist(lapply(datasets, function(x) x %>% distinct(cluster) %>% nrow()))
# Empty list to store the results for each dataset in the list "datasets"
datasets_results <- vector(mode = "list", length = length(datasets))
#for(i in 1:length(datasets)) {
for(i in 1:10) {
results <- train_rkmeans(datasets[[i]], number_of_clusters[i])
datasets_results[[i]] <- results
}
saveRDS(datasets_results, "clustering_web/datasets_results_v2.rds")
# For each dataset, creates a matrix where the rows represent the
# distance measure use for the clustering process
# The row shows the error calculated with each of the distance measures for
# every version of the clustering
results_dataset_errors <- lapply(datasets_results[1:10], calculate_errors)
names(results_dataset_errors) <- names(datasets[1:10])
results_dataset_errors_sorted <- lapply(results_dataset_errors, sorted_errors_by_dataset)
# Create ranking
(rankingsOfErrors <- lapply(results_dataset_errors_sorted, function(x) lapply(x, ranking)))
library(clusterlab)
library(tidyverse)
# 1830 la peor es Euclídea!!!!
#2456
#1617
the_seed <- 2456
# Create a dataset of 2 varibles with 5 clustes of three points each
data <- clusterlab(centers = 5, # the number of clusters to simulate
# the number of units of the radius of the circle on which the clusters are generated
r = 2,
# the number of samples in each cluster
numbervec = c(3, 3, 3, 3, 3),
# standard deviation of each cluster
sdvec = c(1, 3, 2, 1, 1),
alphas = c(3, 5, 1, 4, 2),
# the number of features for the data
features = 2,
seed = the_seed, showplots = FALSE)
(points <- as_tibble(t(data$synthetic_data)) %>% rename(x = 1, y = 2))
#normalize <- function(x){((x-min(x))/(max(x)-min(x)))} # this is already done in train_rkmeans
#points <- as_tibble(apply(points, 2, normalize))
points <- points %>% mutate(cluster = data$identity_matrix$cluster)
# Load the methods just in case...
dyn.load("02.method/distances/distances.so")
dyn.load("02.method/rkmeans/rkmeans.so")
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
errors <- calculate_errors(out_points)
errors <- sorted_errors_by_dataset(errors)
rankingsOfErrors <- lapply(errors, ranking)
rankingsOfErrors <- profile_of_rankings(Reduce(bind_rows, rankingsOfErrors))
rankingsOfErrors_borda <- borda_count(rankingsOfErrors)
rankingsOfErrors_borda
class(rankingsOfErrors_borda)
str_replace_all(print(rankingsOfErrors_borda), ">", "\sim")
str_replace_all(print(rankingsOfErrors_borda), ">", "\\sim")
str_replace_all(print(rankingsOfErrors_borda), ">", "\\\sim")
str_replace_all(print(rankingsOfErrors_borda), ">", "\\\\sim")
print(str_replace_all(print(rankingsOfErrors_borda), ">", "\\\\sim"))
toLatex(str_replace_all(print(rankingsOfErrors_borda), ">", "\\\\sim"))
?toLatex
rankingsOfErrors_borda
writeLines(str_replace_all(print(rankingsOfErrors_borda), ">", "\\\\sim"))
ranking_to_latex <- function(ranking) {
ranking <- str_replace_all(print(rankingsOfErrors_borda), ">", "\\\\succ")
ranking <- str_replace_all(print(rankingsOfErrors_borda), "~", "\\\\sim")
return(ranking)
}
ranking_to_latex <- function(ranking) {
ranking <- str_replace_all(print(rankingsOfErrors_borda), ">", "\\\\succ")
ranking <- str_replace_all(print(rankingsOfErrors_borda), "~", "\\\\sim")
#ranking
return(writeLines(ranking))
}
ranking_to_latex(rankingsOfErrors_borda)
ranking_to_latex <- function(ranking) {
ranking <- str_replace_all(print(rankingsOfErrors_borda), ">", "\\\\succ")
ranking <- str_replace_all(print(ranking), "~", "\\\\sim")
writeLines(ranking)
invisible()
}
ranking_to_latex(rankingsOfErrors_borda)
ranking_to_latex <- function(ranking) {
ranking <- str_replace_all(print(rankingsOfErrors_borda), ">", "\\\\succ")
ranking <- str_replace_all(print(ranking), "~", "\\\\sim")
writeLines(ranking)
invisible(ranking)
}
ranking_to_latex(rankingsOfErrors_borda)
ranking_to_latex <- function(ranking) {
ranking <- str_replace_all(print(rankingsOfErrors_borda), ">", "\\\\succ")
ranking <- str_replace_all(print(ranking), "~", "\\\\sim")
#writeLines(ranking)
invisible(ranking)
}
ranking_to_latex(rankingsOfErrors_borda)
ranking_to_latex <- function(ranking) {
ranking <- str_replace_all(print(rankingsOfErrors_borda), ">", "\\\\succ")
ranking <- str_replace_all(print(ranking), "~", "\\\\sim")
writeLines(ranking)
invisible(0)
}
ranking_to_latex(rankingsOfErrors_borda)
ranking_to_latex <- function(ranking) {
ranking <- str_replace_all(print(rankingsOfErrors_borda), ">", "\\\\succ")
ranking <- str_replace_all(print(ranking), "~", "\\\\sim")
cat(ranking)
invisible(0)
}
ranking_to_latex <- function(ranking) {
ranking <- str_replace_all(rankingsOfErrors_borda, ">", "\\\\succ")
ranking <- str_replace_all(ranking, "~", "\\\\sim")
cat(ranking)
invisible(0)
}
ranking_to_latex(rankingsOfErrors_borda)
ranking_to_latex <- function(ranking) {
ranking <- print(rankingsOfErrors_borda)
ranking <- str_replace_all(ranking, ">", "\\\\succ")
ranking <- str_replace_all(ranking, "~", "\\\\sim")
cat(ranking)
invisible(0)
}
ranking_to_latex(rankingsOfErrors_borda)
ranking_to_latex <- function(ranking) {
ranking <- print(rankingsOfErrors_borda)
ranking <- str_replace_all(ranking, ">", "\\\\succ")
ranking <- str_replace_all(ranking, "~", "\\\\sim")
ranking <- str_replace_all(ranking, ".*", "$$.*$$")
cat(ranking)
invisible(0)
}
ranking_to_latex(rankingsOfErrors_borda)
ranking_to_latex <- function(ranking) {
ranking <- print(rankingsOfErrors_borda)
ranking <- str_replace_all(ranking, ">", "\\\\succ")
ranking <- str_replace_all(ranking, "~", "\\\\sim")
ranking <- str_replace(ranking, ".*", "$$.*$$")
cat(ranking)
invisible(0)
}
ranking_to_latex(rankingsOfErrors_borda)
ranking_to_latex <- function(ranking) {
ranking <- print(rankingsOfErrors_borda)
ranking <- str_replace_all(ranking, ">", "\\\\succ")
ranking <- str_replace_all(ranking, "~", "\\\\sim")
ranking <- str_replace(ranking, ".*", "$$.*$$")
cat(ranking)
invisible(0)
}
ranking_to_latex(rankingsOfErrors_borda)
ranking_to_latex <- function(ranking) {
ranking <- print(rankingsOfErrors_borda)
ranking <- str_replace_all(ranking, ">", "\\\\succ")
ranking <- str_replace_all(ranking, "~", "\\\\sim")
ranking <- paste0("$$", ranking, "$$")
cat(ranking)
invisible(0)
}
ranking_to_latex(rankingsOfErrors_borda)
errors
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
errors <- calculate_errors(out_points)
errors
xtable(errors, digits = 3, caption = "Points of the dataset")
library(xtable)
xtable(errors, digits = 3, caption = "Points of the dataset")
# Input: results of one datasets, taken from a single
# element of the list datasets_results
# Calculates for each distance that was used for training the dataset the
# errors computed which each of the distance
calculate_errors <- function(results_of_one_dataset) {
errors_one_dataset <- sapply(results_of_one_dataset, function(x) x$tot.withinss)
rownames(errors_one_dataset) <- c(paste0("error_d", distances[selected_distances]))
errors_one_dataset
#colSums(errorsd1)
}
xtable(errors, digits = 3, caption = "Points of the dataset")
library(clusterlab)
library(tidyverse)
# 1830 la peor es Euclídea!!!!
#2456
#1617
the_seed <- 2456
# Create a dataset of 2 varibles with 5 clustes of three points each
data <- clusterlab(centers = 5, # the number of clusters to simulate
# the number of units of the radius of the circle on which the clusters are generated
r = 2,
# the number of samples in each cluster
numbervec = c(3, 3, 3, 3, 3),
# standard deviation of each cluster
sdvec = c(1, 3, 2, 1, 1),
alphas = c(3, 5, 1, 4, 2),
# the number of features for the data
features = 2,
seed = the_seed, showplots = FALSE)
(points <- as_tibble(t(data$synthetic_data)) %>% rename(x = 1, y = 2))
#normalize <- function(x){((x-min(x))/(max(x)-min(x)))} # this is already done in train_rkmeans
#points <- as_tibble(apply(points, 2, normalize))
points <- points %>% mutate(cluster = data$identity_matrix$cluster)
# Load the methods just in case...
dyn.load("02.method/distances/distances.so")
dyn.load("02.method/rkmeans/rkmeans.so")
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
errors <- calculate_errors(out_points)
errors <- sorted_errors_by_dataset(errors)
rankingsOfErrors <- lapply(errors, ranking)
rankingsOfErrors <- profile_of_rankings(Reduce(bind_rows, rankingsOfErrors))
rankingsOfErrors_borda <- borda_count(rankingsOfErrors)
#for(n in 1:5000) {
# Clustering with rkmeans
set.seed(the_seed)
out_points <- train_rkmeans(points, 5, iter.max = 1)
errors <- calculate_errors(out_points)
errors
xtable(errors, digits = 3, caption = "Points of the dataset")
print(xtable(errors, digits = 3, caption = "Points of the dataset"), include.rownames = FALSE)
print(xtable(errors, digits = 3, caption = "Points of the dataset"), row_number = FALSE)
